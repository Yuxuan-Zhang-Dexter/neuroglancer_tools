{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Developing Neuroglancer Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from PIL import ImageFile\n",
    "import numpy as np\n",
    "import os\n",
    "import neuroglancer\n",
    "import numpy as np\n",
    "import imageio\n",
    "import h5py\n",
    "from cloudvolume import CloudVolume\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "import webbrowser\n",
    "import tempfile\n",
    "from scipy.ndimage import label, generate_binary_structure, find_objects, center_of_mass\n",
    "from scipy.spatial.distance import euclidean\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directories and output files\n",
    "raw_image_dir = '/media/mitochondria/Elements/spineheads/raw_images'\n",
    "segmentation_dir = '/media/mitochondria/Elements/spineheads/segmentations'\n",
    "raw_output_file = './dataset/raw_images_h5/all_raw_images.h5'\n",
    "seg_output_file = './dataset/seg_images_h5/all_seg_images.h5'\n",
    "seg_24bit_output_file = './dataset/seg_images_h5/all_seg_24_images.h5'\n",
    "n = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "def choose_first_n_images(file_path, dataset_name, n, array_dtype = None):\n",
    "    with h5py.File(file_path, 'r') as fl:\n",
    "        tmp_dataset = fl[dataset_name]\n",
    "        images = []\n",
    "        for i in range(n):\n",
    "            images.append(tmp_dataset[i])\n",
    "        if array_dtype is None:\n",
    "            return np.array(images)\n",
    "        return np.array(images, dtype = array_dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load raw image and segmentation.\n",
      "(5, 15260, 15217) (5, 15260, 15217)\n",
      "http://localhost:9999/v/9795f4ba1fdfd731c11492e0f2df89255f646323/\n"
     ]
    }
   ],
   "source": [
    "ip = 'localhost'\n",
    "port = 9999\n",
    "neuroglancer.set_server_bind_address(bind_address=ip, bind_port=port)\n",
    "viewer = neuroglancer.Viewer()\n",
    "\n",
    "res = neuroglancer.CoordinateSpace(\n",
    "    names=['z', 'y', 'x'],\n",
    "    units=['nm', 'nm', 'nm'],\n",
    "    scales=[60, 4, 4]\n",
    ")\n",
    "\n",
    "print('Load raw image and segmentation.')\n",
    "im = choose_first_n_images(raw_output_file, 'raw_images', n)\n",
    "gt = choose_first_n_images(seg_output_file, 'seg_images', n, array_dtype=np.uint32)\n",
    "gt_copy = gt.copy()\n",
    "\n",
    "print(im.shape, gt.shape)\n",
    "\n",
    "def ngLayer(data, res, oo=[0, 0, 0], tt='segmentation'):\n",
    "    return neuroglancer.LocalVolume(data, dimensions=res, volume_type=tt, voxel_offset=oo)\n",
    "im_layer = ngLayer(im, res, tt='image')\n",
    "gt_layer = ngLayer(gt, res, tt='segmentation')\n",
    "with viewer.txn() as s:\n",
    "    s.layers.append(name='im', layer=im_layer)\n",
    "    s.layers.append(name='gt', layer=gt_layer)\n",
    "\n",
    "\n",
    "print(viewer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # - Test Visualizing RGB Segmentation\n",
    "# ip = 'localhost'\n",
    "# port = 8888\n",
    "# neuroglancer.set_server_bind_address(bind_address=ip, bind_port=port)\n",
    "# viewer_rgb = neuroglancer.Viewer()\n",
    "# # assume a viewer with is already created\n",
    "\n",
    "# # coordinate space for gray-scale volume (z,y,x)\n",
    "# res0 = neuroglancer.CoordinateSpace(\n",
    "#         names=['z', 'y', 'x'],\n",
    "#         units=['nm', 'nm', 'nm'],\n",
    "#         scales=[60, 4, 4])\n",
    "\n",
    "# # coordinate space for RGB volume (c,z,y,x)\n",
    "# res1 = neuroglancer.CoordinateSpace(\n",
    "#         names=['c^', 'z', 'y', 'x'],\n",
    "#         units=['', 'nm', 'nm', 'nm'],\n",
    "#         scales=[3, 60, 4, 4])\n",
    "\n",
    "# im_rgb = choose_first_n_images(seg_24bit_output_file, 'seg_images', n, array_dtype = np.uint32)\n",
    "# im_rgb = np.transpose(im_rgb.copy(), (3, 0, 1, 2))\n",
    "\n",
    "\n",
    "# def ngLayer(data,res,oo=[0,0,0],tt='segmentation'):\n",
    "#     return neuroglancer.LocalVolume(data,dimensions=res,volume_type=tt,voxel_offset=oo)\n",
    "\n",
    "# with viewer_rgb.txn() as s:\n",
    "#     # im: 3d array in (z,y,x). im_rgb: 4d array in (c,z,y,x), c=3\n",
    "#     s.layers.append(name='im',layer=ngLayer(im,res0,tt='image')),\n",
    "#     # s.layers.append(name='im_rgb',layer=ngLayer(im_rgb,res1,oo=[0,0,0,0],tt='image'),\n",
    "#     # shader=\"\"\"\n",
    "#     #     void main() {\n",
    "#     #     emitRGB(vec3(toNormalized(getDataValue(0)),\n",
    "#     #     toNormalized(getDataValue(1)),\n",
    "#     #     toNormalized(getDataValue(2))));\n",
    "#     #     }\n",
    "#     # \"\"\"\n",
    "#     # )\n",
    "#     s.layers.append(name='im_rgb',layer=ngLayer(im_rgb,res1,oo=[0,0,0,0],tt='segmentation'))\n",
    "# print(viewer_rgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Develop basic functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # - show mouse voxel and selected layer value\n",
    "# num_actions = 0\n",
    "# def my_action(s):\n",
    "#     global num_actions\n",
    "#     num_actions += 1\n",
    "#     with viewer.config_state.txn() as st:\n",
    "#       st.status_messages['mouse_info'] = ('Got action %d: mouse position = %r selected value = %s' %\n",
    "#                                      (num_actions, s.mouse_voxel_coordinates, s.selected_values))\n",
    "# viewer.actions.add('mouse_coordinate', my_action)\n",
    "# with viewer.config_state.txn() as s:\n",
    "#     s.input_event_bindings.viewer['keyt'] = 'mouse_coordinate'\n",
    "#     s.status_messages['mouse_info'] = 'Mouse Info'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # - mousedown is problematic\n",
    "# def add_annotation(s):\n",
    "\n",
    "#     with viewer.config_state.txn() as st:\n",
    "#         st.status_messages['annotation info'] = ('Got action: mouse position = %r selected value = %s' %\n",
    "#                                                  (s.mouse_voxel_coordinates, s.selected_values))\n",
    "# viewer.actions.add(\"add-annotation\", add_annotation)\n",
    "# with viewer.config_state.txn() as s:\n",
    "#     s.input_event_bindings.viewer['shift+keyq'] = \"add-annotation\"\n",
    "#     s.status_messages['annotation info'] = ('start to add annotations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # - Center Function - how check all available keys\n",
    "# def center_image(sts):\n",
    "#     with viewer.txn() as s:\n",
    "#         s.voxel_coordinates = [0, gt.shape[1]/2, gt.shape[2]/2]\n",
    "# viewer.actions.add('center_image', center_image)\n",
    "# with viewer.config_state.txn() as st:\n",
    "#     st.input_event_bindings.viewer['shift+keyc'] = 'center_image'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # - Generate All Segmentation\n",
    "# all_unique_ids = np.unique(gt)\n",
    "# def generate_all_meshes(st):\n",
    "#     with viewer.config_state.txn() as st:\n",
    "#         st.status_messages['generate_meshes'] = (f'Start generating all meshes')\n",
    "#     with viewer.txn() as s:\n",
    "#         for i in all_unique_ids:\n",
    "#             s.layers['segmentation'].segments.add(i)\n",
    "#     with viewer.config_state.txn() as st:\n",
    "#         st.status_messages['generate_meshes'] = (f'Finish generating all meshes')\n",
    "# viewer.actions.add('generate_all_meshes', generate_all_meshes)\n",
    "# with viewer.config_state.txn() as st:\n",
    "#     st.input_event_bindings.viewer['control+shift+keyg'] = 'generate_all_meshes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # - Screenshot 3D meshes\n",
    "# from ipywidgets import Image\n",
    "# count = 0\n",
    "# screenshot_dir = './screenshot'\n",
    "# def screenshot_3D_meshes(st):\n",
    "#     global count\n",
    "#     global screenshot_dir\n",
    "#     if not os.path.exists(screenshot_dir):\n",
    "#         os.makedirs(screenshot_dir)\n",
    "#     with viewer.txn() as s:\n",
    "#         s.layout = '3d'\n",
    "#         s.projection_scale = 5000\n",
    "#     screenshot = viewer.screenshot(size=[1000, 1000])\n",
    "#     screenshot_image = Image(value=screenshot.screenshot.image)\n",
    "#     screenshot_image.save(screenshot_dir + f'/screenshot_{count:03d}.png')\n",
    "#     count += 1\n",
    "# viewer.actions.add('screenshot_3D_meshes', screenshot_3D_meshes)\n",
    "# with viewer.config_state.txn() as st:\n",
    "#     st.input_event_bindings.viewer['shift+keyf'] = 'screenshot_3D_meshes'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Develop Merge and Cut Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class merge_split_function:\n",
    "    def __init__(self, viewer, gt, res, gt_layer, min_size = 40):\n",
    "        self.viewer = viewer\n",
    "        self.gt = gt\n",
    "        self.res = res\n",
    "        self.annotation_points = []\n",
    "        self.annotation_order = 0\n",
    "        self.gt_layer = gt_layer\n",
    "        self.max_id = np.max(gt)\n",
    "        self.min_size = min_size\n",
    "\n",
    "\n",
    "\n",
    "        # - Adding actions\n",
    "        self.viewer.actions.add(\"add_annotation\", self.add_annotation)\n",
    "        self.viewer.actions.add(\"merge_segments\", self.merge_segments)\n",
    "        self.viewer.actions.add(\"split_segments\", self.split_segments)\n",
    "\n",
    "        # - Binding keys\n",
    "        with self.viewer.config_state.txn() as s:\n",
    "            s.input_event_bindings.viewer['shift+keyq'] = \"add_annotation\"\n",
    "            s.status_messages['add annotation info'] = \"press shift+keyq to select segmentation\"\n",
    "            s.input_event_bindings.viewer['control+shift+keym'] = \"merge_segments\"\n",
    "            s.input_event_bindings.viewer['control+shift+keys'] = 'split_segments'\n",
    "            s.status_messages['merge info'] = \"press control+shift+m to merge segmentation\"\n",
    "            s.status_messages['split info'] = \"press control+shift+s to split segmentation\"\n",
    "    \n",
    "    def add_annotation(self, s):\n",
    "        coordinates = s.mouse_voxel_coordinates\n",
    "        segment_id = s.selected_values.get(\"gt\").value\n",
    "\n",
    "        with self.viewer.config_state.txn() as st:\n",
    "            st.status_messages['annotation info'] = ('Selected segmentation: mouse position = %r selected value = %s' %\n",
    "                                                (s.mouse_voxel_coordinates, s.selected_values.get(\"gt\").value))\n",
    "\n",
    "        self.annotation_points.append((coordinates, segment_id))\n",
    "        print(f\"Added annotation at {coordinates} with segment ID {segment_id}\")\n",
    "\n",
    "        if len(self.annotation_points) > 2:\n",
    "            with self.viewer.config_state.txn() as st:\n",
    "                st.status_messages['annotation info'] = (f'Too much annotation points. It will automatically delete all points.')\n",
    "            print(f'Too much annotation points. It will automatically delete all points.')\n",
    "            self.annotation_points = []\n",
    "\n",
    "    def merge_segments(self, s):\n",
    "        if len(self.annotation_points) == 2:\n",
    "            with self.viewer.config_state.txn() as st:\n",
    "                st.status_messages['merge info'] = ('Start merging')\n",
    "            segments = set(annotation[1] for annotation in self.annotation_points)\n",
    "\n",
    "            segment_ids = list(segments)\n",
    "            target_segment_id = segment_ids[0]\n",
    "            merge_segment_id = segment_ids[1]\n",
    "\n",
    "            print(f\"current merge segment id: {merge_segment_id}\")\n",
    "            with self.viewer.config_state.txn() as st:\n",
    "                st.status_messages['merge info'] = f\"current merge segment id: {merge_segment_id}\"\n",
    "            self.gt[self.gt == merge_segment_id] = target_segment_id\n",
    "            self.gt_layer.invalidate()\n",
    "            self.annotation_points = []\n",
    "            with self.viewer.config_state.txn() as st:\n",
    "                st.status_messages['merge info'] = ('Merging done!')\n",
    "            print('Merging done!')\n",
    "\n",
    "\n",
    "    def split_segments(self, s):\n",
    "        if len(self.annotation_points) != 2:\n",
    "            print(\"Error: Exactly two annotation points are required to perform a split. \")\n",
    "            return \n",
    "        print(f\"check coordinate: {self.annotation_points[0][0]}\")\n",
    "        if self.annotation_points[0][1] == self.annotation_points[1][1]:\n",
    "            with self.viewer.config_state.txn() as st:\n",
    "                st.status_messages['split info'] = f\"Start splitting\"\n",
    "            segment_id = self.annotation_points[0][1]\n",
    "            with self.viewer.config_state.txn() as st:\n",
    "                st.status_messages['split info'] = f\"current split segment id: {segment_id}\"\n",
    "            print(f\"current split segment id: {segment_id}\")\n",
    "            mask = self.gt == segment_id\n",
    "            \n",
    "            # - check mouse id\n",
    "            mouse_coord_1 = self.annotation_points[0][0]\n",
    "            mouse_coord_2 = self.annotation_points[1][0]\n",
    "            mouse_coord_2d_1 = np.round(mouse_coord_1[1:])\n",
    "            mouse_coord_2d_2 = np.round(mouse_coord_2[1:])\n",
    "            target_z = np.round(mouse_coord_1[0])\n",
    "\n",
    "            non_zero_slices = []\n",
    "            z_list = []\n",
    "            for i in range(mask.shape[0]):\n",
    "\n",
    "                slice_2d = mask[i, :, :]\n",
    "\n",
    "                if np.any(slice_2d > 0):\n",
    "                    z_list.append(i)\n",
    "                    non_zero_slices.append(slice_2d)\n",
    "\n",
    "            # - split instance slice by slice\n",
    "            # - set close to the first mouse coordiante, the segment id doesn't need to change\n",
    "            for non_zero_slice, z_id in zip(non_zero_slices, z_list):\n",
    "                # - filter out tiny points\n",
    "                non_zero_slice = non_zero_slice.astype(np.uint8)\n",
    "                nlabels, labels, stats, centroids = cv2.connectedComponentsWithStats(non_zero_slice, connectivity=8)\n",
    "                filtered_slice = np.zeros_like(non_zero_slice)\n",
    "                for label_id in range(1, nlabels):\n",
    "                    area = stats[label_id, cv2.CC_STAT_AREA]\n",
    "                    if area >= self.min_size:\n",
    "                        filtered_slice[labels == label_id] = 1\n",
    "\n",
    "                labeled_array, num_features = label(filtered_slice, structure=generate_binary_structure(2, 2))\n",
    "                object_slices = find_objects(labeled_array)\n",
    "\n",
    "                if num_features > 2:\n",
    "                    print(\"there are more than two splitting items.\")\n",
    "                    return\n",
    "                else:\n",
    "                    reshape_labeled_array = labeled_array[np.newaxis, :, :]\n",
    "                    if num_features == 1:\n",
    "                        center_coordinate_1 = center_of_mass(labeled_array == 1)\n",
    "                        distance_1 = euclidean(center_coordinate_1, mouse_coord_2d_1)\n",
    "                        distance_2 = euclidean(center_coordinate_1, mouse_coord_2d_2)\n",
    "\n",
    "                        if distance_1 > distance_2:\n",
    "                            y_start, y_stop = object_slices[0][0].start, object_slices[0][0].stop\n",
    "                            x_start, x_stop = object_slices[0][1].start, object_slices[0][1].stop\n",
    "                            self.gt[z_id, y_start:y_stop, x_start:x_stop][reshape_labeled_array[0, y_start:y_stop, x_start:x_stop] == 1 ] = self.max_id + 1\n",
    "\n",
    "                    elif num_features == 2:\n",
    "                        center_coordinate_1 = center_of_mass(labeled_array == 1)\n",
    "                        center_cooridnate_2 = center_of_mass(labeled_array == 2)\n",
    "                        distance_mouse_1 = euclidean(center_coordinate_1, mouse_coord_2d_1)\n",
    "                        distance_mouse_2 = euclidean(center_cooridnate_2, mouse_coord_2d_1)\n",
    "\n",
    "                        if distance_mouse_1 > distance_mouse_2:\n",
    "                            y_start, y_stop = object_slices[0][0].start, object_slices[0][0].stop\n",
    "                            x_start, x_stop = object_slices[0][1].start, object_slices[0][1].stop\n",
    "                            self.gt[z_id, y_start:y_stop, x_start:x_stop][reshape_labeled_array[0, y_start:y_stop, x_start:x_stop] == 1] = self.max_id + 1\n",
    "                        else:\n",
    "                            y_start, y_stop = object_slices[1][0].start, object_slices[1][0].stop\n",
    "                            x_start, x_stop = object_slices[1][1].start, object_slices[1][1].stop\n",
    "                            self.gt[z_id, y_start:y_stop, x_start:x_stop][reshape_labeled_array[0, y_start:y_stop, x_start:x_stop] == 2] = self.max_id + 1            \n",
    "        else:\n",
    "            print(\"Error: Exactly two annotation points with the same segment id are required to perform a split. \")\n",
    "            return   \n",
    "\n",
    "        self.max_id += 1\n",
    "        self.gt_layer.invalidate()\n",
    "        self.annotation_points = []\n",
    "        with self.viewer.config_state.txn() as st:\n",
    "            st.status_messages['split info'] = f\"Splitting done!\"\n",
    "        print(\"Splitting done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # - Test 3D split function\n",
    "# max_id = 10000\n",
    "# gt_copy = gt.copy()\n",
    "# test_id1 = 2359\n",
    "# test_id2 = 2387\n",
    "# mouse_coord_1 = [4.5000000e+00, 7.3205005e+03, 7.5179995e+03]\n",
    "# mouse_coord_2 = [4.5000000e+00, 9.3205005e+03, 7.5179995e+03]\n",
    "# mouse_coord_1 = np.round(mouse_coord_1[1:])\n",
    "# mouse_coord_2 = np.round(mouse_coord_2[1:])\n",
    "# gt_copy[gt_copy == test_id1] = test_id2\n",
    "# mask = gt_copy == test_id2\n",
    "# min_area = 40\n",
    "\n",
    "\n",
    "# non_zero_slices = []\n",
    "# z_list = []\n",
    "# for i in range(mask.shape[0]):\n",
    "\n",
    "#     slice_2d = mask[i, :, :]\n",
    "\n",
    "#     if np.any(slice_2d > 0):\n",
    "#         z_list.append(i)\n",
    "#         non_zero_slices.append(slice_2d)\n",
    "\n",
    "# # - split instance slice by slice\n",
    "# # - set close to the first mouse coordiante, the segment id doesn't need to change\n",
    "# count = 0\n",
    "# for non_zero_slice, z_id in zip(non_zero_slices, z_list):\n",
    "#     non_zero_slice = non_zero_slice.astype(np.uint8)\n",
    "#     nlabels, labels, stats, centroids = cv2.connectedComponentsWithStats(non_zero_slice, connectivity=8)\n",
    "    \n",
    "    \n",
    "#     filtered_slice = np.zeros_like(non_zero_slice)\n",
    "#     for label_id in range(1, nlabels):\n",
    "#         area = stats[label_id, cv2.CC_STAT_AREA]\n",
    "#         if area >= min_area:\n",
    "#             filtered_slice[labels == label_id] = 1\n",
    "#     labeled_array, num_features = label(non_zero_slice, structure=generate_binary_structure(2, 2))\n",
    "#     filter_labeled_array, filter_num_features = label(filtered_slice, structure=generate_binary_structure(2, 2))\n",
    "#     object_slices = find_objects(labeled_array)\n",
    "\n",
    "#     print(count)\n",
    "#     print(f\"the number of labels: {num_features}\")\n",
    "#     print(f\"cv2 number of labels: {nlabels}\")\n",
    "#     print(f\"the number of filtered labels: {filter_num_features}\")\n",
    "\n",
    "\n",
    "#     if num_features > 2:\n",
    "#         print(\"there are more than two splitting items.\")\n",
    "#     else:\n",
    "#         reshape_labeled_array = labeled_array[np.newaxis, :, :]\n",
    "#         if num_features == 1:\n",
    "#             center_coordinate_1 = center_of_mass(labeled_array == 1)\n",
    "#             distance_1 = euclidean(center_coordinate_1, mouse_coord_1)\n",
    "#             distance_2 = euclidean(center_coordinate_1, mouse_coord_2)\n",
    "\n",
    "#             if distance_1 > distance_2:\n",
    "#                 y_start, y_stop = object_slices[0][0].start, object_slices[0][0].stop\n",
    "#                 x_start, x_stop = object_slices[0][1].start, object_slices[0][1].stop\n",
    "#                 gt_copy[z_id, y_start:y_stop, x_start:x_stop][reshape_labeled_array[0, y_start:y_stop, x_start:x_stop] > 0 ] = max_id + 1\n",
    "\n",
    "#         elif num_features == 2:\n",
    "#             center_coordinate_1 = center_of_mass(labeled_array == 1)\n",
    "#             center_cooridnate_2 = center_of_mass(labeled_array == 2)\n",
    "#             distance_mouse_1 = euclidean(center_coordinate_1, mouse_coord_1)\n",
    "#             distance_mouse_2 = euclidean(center_cooridnate_2, mouse_coord_1)\n",
    "\n",
    "#             if distance_mouse_1 > distance_mouse_2:\n",
    "#                 y_start, y_stop = object_slices[0][0].start, object_slices[0][0].stop\n",
    "#                 x_start, x_stop = object_slices[0][1].start, object_slices[0][1].stop\n",
    "#                 gt_copy[z_id, y_start:y_stop, x_start:x_stop][reshape_labeled_array[0, y_start:y_stop, x_start:x_stop] > 0] = max_id + 1\n",
    "#             else:\n",
    "#                 y_start, y_stop = object_slices[1][0].start, object_slices[1][0].stop\n",
    "#                 x_start, x_stop = object_slices[1][1].start, object_slices[1][1].stop\n",
    "#                 gt_copy[z_id, y_start:y_stop, x_start:x_stop][reshape_labeled_array[0, y_start:y_stop, x_start:x_stop] > 0] = max_id + 1\n",
    "#     count += 1\n",
    "\n",
    "# max_id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge_split_function(viewer, gt, res, gt_layer)\n",
    "webbrowser.open_new_tab(str(viewer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # - add local annotation layer\n",
    "# with viewer.txn() as s:\n",
    "#     s.layers['annotations'] = neuroglancer.AnnotationLayer()\n",
    "#     annotations = s.layers['annotations'].annotations\n",
    "#     s.selected_layer.layer = \"annotations\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # - Add an annotation layer\n",
    "# import neuroglancer.static_file_server\n",
    "# import neuroglancer.write_annotations\n",
    "# tempdir = tempfile.mkdtemp()\n",
    "# server = neuroglancer.static_file_server.StaticFileServer(\n",
    "#         static_dir=tempdir, bind_address=ip or \"127.0.0.1\", daemon=True\n",
    "#     )\n",
    "# with viewer.txn() as s:\n",
    "#     s.layers[\"annotations\"] = neuroglancer.AnnotationLayer(\n",
    "#         source=f\"precomputed://{server.url}\",\n",
    "#         tab=\"rendering\",\n",
    "#         shader=\"\"\"\n",
    "# void main() {\n",
    "#   setColor(prop_point_color());\n",
    "#   setPointMarkerSize(prop_size());\n",
    "# }\n",
    "# \"\"\",\n",
    "#     )\n",
    "#     s.selected_layer.layer = \"annotations\"\n",
    "#     s.selected_layer.visible = True\n",
    "#     s.show_slices = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def write_some_annotations(\n",
    "#     output_dir: str, coordinate_space: neuroglancer.CoordinateSpace, target_coordinate\n",
    "# ):\n",
    "#     writer = neuroglancer.write_annotations.AnnotationWriter(\n",
    "#         coordinate_space=coordinate_space,\n",
    "#         annotation_type=\"point\",\n",
    "#         properties=[\n",
    "#             neuroglancer.AnnotationPropertySpec(id=\"size\", type=\"float32\"),\n",
    "#             neuroglancer.AnnotationPropertySpec(id=\"cell_type\", type=\"uint16\"),\n",
    "#             neuroglancer.AnnotationPropertySpec(id=\"point_color\", type=\"rgba\"),\n",
    "#         ],\n",
    "#     )\n",
    "\n",
    "#     writer.add_point(target_coordinate, size=50, cell_type=16, point_color=(255, 255, 255, 255))\n",
    "#     writer.write(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write_some_annotations(output_dir=tempdir, coordinate_space=res, target_coordinate=[0, gt.shape[1]/2, gt.shape[2]/2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import neuroglancer.random_token\n",
    "\n",
    "\n",
    "# class Annotator:\n",
    "#     def __init__(self, viewer, gt, res):\n",
    "#         self.viewer = viewer\n",
    "#         self.gt = gt\n",
    "#         self.res = res\n",
    "#         self.annotation_points = []\n",
    "#         self.annotation_order = 0\n",
    "\n",
    "#         # - Adding actions\n",
    "#         self.viewer.actions.add(\"add-annotation\", self.add_annotation)\n",
    "#         # self.viewer.actions.add(\"merge-segments\", self.merge_segments)\n",
    "#         # self.viewer.actions.add(\"clear-annotations\", self.clear_annotations)\n",
    "\n",
    "#         # - Binding keys\n",
    "#         with self.viewer.config_state.txn() as s:\n",
    "#             s.input_event_bindings.viewer['control+shift+mousedown0'] = \"add-annotation\"\n",
    "#             s.input_event_bindings.viewer['control+shift+keym'] = \"merge-segments\"\n",
    "#             s.input_event_bindings.viewer['control+keyd'] = \"clear-annotations\"\n",
    "    \n",
    "#     def add_annotation(self, s):\n",
    "#         coordinates = s.mouse_voxel_coordinates\n",
    "#         segment_id = s.selected_values.get(\"gt\")\n",
    "\n",
    "#         if segment_id is None:\n",
    "#             print(f\"No segment found at {coordinates}\")\n",
    "#             return\n",
    "#         with self.viewer.txn() as state:\n",
    "#             pt = neuroglancer.PointAnnotation(point = coordinates, id = f'point{self.annotation_order}')\n",
    "#             annotations.append(pt)\n",
    "#         self.annotation_points.append((coordinates, segment_id))\n",
    "#         self.annotation_order += 1\n",
    "#         print(f\"Added annotation at {coordinates} with segment ID {segment_id}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # - Test add-annotation function\n",
    "# annotator = Annotator(viewer, gt, res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# with viewer.txn() as s:\n",
    "#     s.layers['points'] = neuroglancer.LocalAnnotationLayer(dimensions=res)\n",
    "\n",
    "# num_actions = 0\n",
    "# def logger(s):\n",
    "#     global num_actions\n",
    "#     num_actions += 1\n",
    "#     with viewer.config_state.txn() as st:\n",
    "#         st.status_messages['hello'] = ('Got action %d: mouse position = %r' %\n",
    "#                                     (num_actions, s.mouse_voxel_coordinates))\n",
    "\n",
    "#     print('Log event')\n",
    "#     print('Mouse position: ', np.array(s.mouse_voxel_coordinates))\n",
    "#     print('Layer selected values:', (np.array(list(viewer.state.layers['segmentation'].segments))))\n",
    "#     with viewer.txn() as s:\n",
    "#         point = np.array(s.mouse_voxel_coordinates)\n",
    "#         point_anno = neuroglancer.PointAnnotation(\n",
    "#                          id=repr(point),\n",
    "#                          point=point)\n",
    "#         s.layers['points'].annotations = [point_anno]\n",
    "\n",
    "\n",
    "# viewer.actions.add('logger', logger)\n",
    "# with viewer.config_state.txn() as s:\n",
    "#     s.input_event_bindings.viewer['keyl'] = 'logger'\n",
    "#     s.status_messages['hello'] = 'Add a promt for neuroglancer'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Swap RAM to Disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Helper functions\n",
    "# def choose_first_n_images_disk(file_path, dataset_name, n, output_array):\n",
    "#     with h5py.File(file_path, 'r') as fl:\n",
    "#         tmp_dataset = fl[dataset_name]\n",
    "#         for i in range(n):\n",
    "#             output_array[i] = tmp_dataset[i]\n",
    "\n",
    "# gt_file = 'gt_array.dat'\n",
    "# shape = (100, 15260, 15217)\n",
    "# gt_array = np.memmap(gt_file, dtype = np.uint32, mode = 'w+', shape=shape)\n",
    "# choose_first_n_images_disk(seg_output_file, 'seg_images', 100, gt_array)\n",
    "# gt_array.flush()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # - Get unique ids\n",
    "# chunk_size = 1\n",
    "# for i in range(0, gt_array.shape[0], chunk_size):\n",
    "#     chunk = gt_array[i:i+chunk_size, :, :]\n",
    "#     unique_chunk = np.unique(chunk).astype('unint32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# im_array = choose_first_n_images(raw_output_file, 'raw_images', 100, array_dtype = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ip = 'localhost'\n",
    "# port = 9999\n",
    "# neuroglancer.set_server_bind_address(bind_address=ip, bind_port=port)\n",
    "# viewer = neuroglancer.Viewer()\n",
    "\n",
    "# res = neuroglancer.CoordinateSpace(\n",
    "#     names=['z', 'y', 'x'],\n",
    "#     units=['nm', 'nm', 'nm'],\n",
    "#     scales=[60, 4, 4]\n",
    "# )\n",
    "\n",
    "# print('Load raw image and segmentation.')\n",
    "\n",
    "\n",
    "# def ngLayer(data, res, oo=[0, 0, 0], tt='segmentation'):\n",
    "#     return neuroglancer.LocalVolume(data, dimensions=res, volume_type=tt, voxel_offset=oo)\n",
    "# im_layer = ngLayer(im_array, res, tt='image')\n",
    "# gt_layer = ngLayer(gt_array, res, tt='segmentation')\n",
    "# with viewer.txn() as s:\n",
    "#     s.layers.append(name='im', layer=im_layer)\n",
    "#     s.layers.append(name='gt', layer=gt_layer)\n",
    "\n",
    "\n",
    "# print(viewer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with viewer.txn() as s:\n",
    "#     s.layers['segmentation'].segments.add(204336)\n",
    "#     s.layers['segmentation'].segments.add(213086)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yuxuan_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
