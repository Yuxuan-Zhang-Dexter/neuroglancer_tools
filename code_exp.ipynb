{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro to Neuroglancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:9999/v/ea5eae7de149f0eb10f651da0ea88a28e26fab9c/\n"
     ]
    }
   ],
   "source": [
    "# - Raw Viewer\n",
    "import neuroglancer\n",
    "\n",
    "ip = 'localhost' # or public IP of the machine for sharable display\n",
    "port = 9999 # change to an unused port number\n",
    "neuroglancer.set_server_bind_address(bind_address=ip, bind_port=port)\n",
    "\n",
    "viewer = neuroglancer.Viewer()\n",
    "print(viewer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:9999/v/a95e3d188af11f311b5f7cc402463b813e0c2f43/\n"
     ]
    }
   ],
   "source": [
    "# - Example Viewer\n",
    "import neuroglancer\n",
    "\n",
    "ip = 'localhost' #or public IP of the machine for sharable display\n",
    "port = 9999 #change to an unused port number\n",
    "neuroglancer.set_server_bind_address(bind_address=ip,bind_port=port)\n",
    "\n",
    "viewer = neuroglancer.Viewer()\n",
    "\n",
    "with viewer.txn() as s:\n",
    "    s.layers['image'] = neuroglancer.ImageLayer(source='precomputed://gs://neuroglancer-janelia-flyem-hemibrain/emdata/clahe_yz/jpeg/')\n",
    "    s.layers['segmentation'] = neuroglancer.SegmentationLayer(source='precomputed://gs://neuroglancer-janelia-flyem-hemibrain/v1.0/segmentation', selected_alpha=0.3)\n",
    "\n",
    "print(viewer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - Using Local Dataset Viewer\n",
    "# import neuroglancer\n",
    "# import numpy as np\n",
    "# import imageio\n",
    "# import h5py\n",
    "\n",
    "# ip = 'localhost' #or public IP of the machine for sharable display\n",
    "# port = 9999 #change to an unused port number\n",
    "# neuroglancer.set_server_bind_address(bind_address=ip,bind_port=port)\n",
    "# viewer=neuroglancer.Viewer()\n",
    "\n",
    "# # SNEMI (# 3d vol dim: z,y,x)\n",
    "# D0='./'\n",
    "# res = neuroglancer.CoordinateSpace(\n",
    "#         names=['z', 'y', 'x'],\n",
    "#         units=['nm', 'nm', 'nm'],\n",
    "#         scales=[30, 6, 6])\n",
    "\n",
    "# print('load im and gt segmentation')\n",
    "# im = imageio.volread(D0+'train-input.tif')\n",
    "# with h5py.File(D0+'train_label.h5', 'r') as fl:\n",
    "#     gt = np.array(fl['main'])\n",
    "# print(im.shape, gt.shape)\n",
    "\n",
    "# def ngLayer(data,res,oo=[0,0,0],tt='segmentation'):\n",
    "#     return neuroglancer.LocalVolume(data,dimensions=res,volume_type=tt,voxel_offset=oo)\n",
    "\n",
    "# with viewer.txn() as s:\n",
    "#     s.layers.append(name='im',layer=ngLayer(im,res,tt='image'))\n",
    "#     s.layers.append(name='gt',layer=ngLayer(gt,res,tt='segmentation'))\n",
    "\n",
    "# print(viewer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load 36 bit Image on Neuroglancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from PIL import ImageFile\n",
    "import numpy as np\n",
    "import os\n",
    "import neuroglancer\n",
    "import numpy as np\n",
    "import imageio\n",
    "import h5py\n",
    "from cloudvolume import CloudVolume\n",
    "from tqdm import tqdm\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - Read and Show one 36 bit image\n",
    "Image.MAX_IMAGE_PIXELS = None\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "raw_image_dir = '/media/mitochondria/Elements/spineheads/raw_images'\n",
    "segmentation_dir = '/media/mitochondria/Elements/spineheads/segmentations'\n",
    "segmentation_24_dir = '/media/mitochondria/Elements/spineheads_24'\n",
    "raw_output_file = '/media/mitochondria/Elements/spineheads/raw_images_h5/all_raw_images.h5'\n",
    "seg_output_file = '/media/mitochondria/Elements/spineheads/seg_images_h5/all_seg_images.h5'\n",
    "seg_24_output_file = '/media/mitochondria/Elements/spineheads/seg_images_h5/all_seg_24_images.h5'\n",
    "split_raw_output_file = './split_raw_h5/split_raw_images.h5'\n",
    "split_raw_output_dir = './split_raw_h5'\n",
    "split_seg_output_file = './split_seg_h5/split_seg_images.h5'\n",
    "split_seg_output_dir = './split_seg_h5'\n",
    "raw_dataset_name = 'raw_images'\n",
    "seg_dataset_name = 'seg_images'\n",
    "n = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks: 100%|██████████| 3/3 [05:26<00:00, 108.75s/file]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined images into /media/mitochondria/Elements/spineheads/seg_images_h5/all_seg_24_images.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# - Convert tiff to hd5\n",
    "def combine_images_to_hdf5(input_dir, output_file, dataset_name, chunk_size=10):\n",
    "    output_dir = os.path.dirname(output_file)\n",
    "    if output_dir and not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    image_files = [f for f in sorted(os.listdir(input_dir)) if f.lower().endswith(('png', 'tiff', 'tif'))]\n",
    "    image_files = image_files\n",
    "    total_images = len(image_files)\n",
    "    if total_images == 0:\n",
    "        print(f\"No images found in {input_dir}.\")\n",
    "        return\n",
    "\n",
    "    # Initialize HDF5 file\n",
    "    with h5py.File(output_file, 'w') as h5file:\n",
    "        for chunk_index in tqdm(range(0, total_images, chunk_size), desc=\"Processing chunks\", unit = \"file\"):\n",
    "            chunk_files = image_files[chunk_index:chunk_index + chunk_size]\n",
    "            images = []\n",
    "\n",
    "            for i in tqdm(range(len(chunk_files)), desc= \"Processing files\", leave = False):\n",
    "                file_name = chunk_files[i]\n",
    "                file_path = os.path.join(input_dir, file_name)\n",
    "                try:\n",
    "                    with Image.open(file_path) as img:\n",
    "                        if file_name.lower().endswith(('tiff', 'tif')) and img.n_frames > 1:\n",
    "                            print(f\"Skipping multi-frame TIFF file: {file_name}\")\n",
    "                            continue\n",
    "                        img_array = np.array(img)\n",
    "                        images.append(img_array)\n",
    "                except Exception as e:\n",
    "                    print(f\"Failed to process image {file_name}: {e}\")\n",
    "                    continue\n",
    "\n",
    "            if chunk_index == 0:\n",
    "                # Create dataset with the shape of the first image\n",
    "                h5file.create_dataset(dataset_name, data=images, maxshape=(None,) + images[0].shape, compression=\"gzip\")\n",
    "            else:\n",
    "                # Resize the dataset to accommodate new data\n",
    "                h5file[dataset_name].resize((h5file[dataset_name].shape[0] + len(images)), axis=0)\n",
    "                h5file[dataset_name][-len(images):] = images\n",
    "\n",
    "            del images\n",
    "            gc.collect()\n",
    "\n",
    "    print(f\"Combined images into {output_file}\")\n",
    "\n",
    "combine_images_to_hdf5(segmentation_24_dir, seg_24_output_file, seg_dataset_name, chunk_size=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - Split 10 Images for Experiments\n",
    "def split_h5_file(input_file_path, dataset_name, output_file_path, n):\n",
    "    with h5py.File(input_file_path, 'r') as fl:\n",
    "        tmp_dataset = fl[dataset_name]\n",
    "        tmp_array = tmp_dataset[:n]\n",
    "    with h5py.File(output_file_path, 'w') as fl2:\n",
    "        fl2.create_dataset(dataset_name, data = tmp_array)\n",
    "\n",
    "\n",
    "split_h5_file(raw_output_file, raw_dataset_name, split_raw_output_file, 10)\n",
    "split_h5_file(seg_output_file, seg_dataset_name, split_seg_output_file, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - Add info file to local dataset\n",
    "# - Try compress choice???, not sure about all parameters like mesh???\n",
    "raw_info = CloudVolume.create_new_info(\n",
    "\tnum_channels = 1,\n",
    "\tlayer_type = 'image', # 'image' or 'segmentation'\n",
    "\tdata_type = 'uint8', # can pick any popular uint\n",
    "\tencoding = 'raw', # see: https://github.com/seung-lab/cloud-volume/wiki/Compression-Choices\n",
    "\tresolution = [ 4, 4, 60 ], # X,Y,Z values in nanometers\n",
    "\tvoxel_offset = [ 0, 0, 0 ], # values X,Y,Z values in voxels\n",
    "\tchunk_size = [ 1024, 1024, 1 ], # rechunk of image X,Y,Z in voxels\n",
    "\tvolume_size = [ 15217, 15260, 10 ], # X,Y,Z size in voxels\n",
    ")\n",
    "\n",
    "raw_vol = CloudVolume(f\"file://{split_raw_output_dir}\", info = raw_info)\n",
    "raw_vol.commit_info()\n",
    "\n",
    "seg_info = CloudVolume.create_new_info(\n",
    "\tnum_channels = 1,\n",
    "\tlayer_type = 'segmentation', # 'image' or 'segmentation'\n",
    "\tdata_type = 'uint32', # can pick any popular uint\n",
    "\tencoding = 'raw', # see: https://github.com/seung-lab/cloud-volume/wiki/Compression-Choices\n",
    "\tresolution = [ 4, 4, 60 ], # X,Y,Z values in nanometers\n",
    "\tvoxel_offset = [ 0, 0, 0 ], # values X,Y,Z values in voxels\n",
    "\tchunk_size = [ 1024, 1024, 1 ], # rechunk of image X,Y,Z in voxels\n",
    "\tvolume_size = [ 15217, 15260, 10 ], # X,Y,Z size in voxels\n",
    "    mesh = 'mesh'\n",
    ")\n",
    "\n",
    "seg_vol = CloudVolume(f\"file://{split_seg_output_dir}\", info = raw_info)\n",
    "seg_vol.commit_info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L\n"
     ]
    }
   ],
   "source": [
    "# - Check raw image bit size unit8 grayscale\n",
    "raw_image_sample = Image.open(raw_image_dir + '/raw_image_000.png')\n",
    "print(raw_image_sample.mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_first_n_images(file_path, dataset_name, n):\n",
    "    with h5py.File(file_path, 'r') as fl:\n",
    "        tmp_dataset = fl[dataset_name]\n",
    "        images = []\n",
    "        for i in range(n):\n",
    "            images.append(tmp_dataset[i])\n",
    "        # if dataset_name == 'raw_images':\n",
    "        #     return np.array(images)\n",
    "        # else:\n",
    "        #     return np.array(images, dtype=np.uint32)\n",
    "        if dataset_name == 'seg_images':\n",
    "            return np.array(images, dtype=np.uint32)\n",
    "        return np.array(images)\n",
    "\n",
    "\n",
    "def neuroglancer_visualize(raw_output_file, seg_output_file):\n",
    "    ip = 'localhost'\n",
    "    port = 9999\n",
    "    neuroglancer.set_server_bind_address(bind_address=ip, bind_port=port)\n",
    "    viewer = neuroglancer.Viewer()\n",
    "\n",
    "    res = neuroglancer.CoordinateSpace(\n",
    "        names=['z', 'y', 'x'],\n",
    "        units=['nm', 'nm', 'nm'],\n",
    "        scales=[60, 4, 4]\n",
    "    )\n",
    "\n",
    "    print('Load raw image and segmentation.')\n",
    "    try:\n",
    "        im = choose_first_n_images(raw_output_file, 'raw_images', n)\n",
    "        gt = choose_first_n_images(seg_output_file, 'seg_images', n)\n",
    "    except FileNotFoundError as e:\n",
    "        print(e)\n",
    "        return\n",
    "\n",
    "    print(im.shape, gt.shape)\n",
    "\n",
    "    def ngLayer(data, res, oo=[0, 0, 0], tt='segmentation'):\n",
    "        return neuroglancer.LocalVolume(data, dimensions=res, volume_type=tt, voxel_offset=oo)\n",
    "\n",
    "    with viewer.txn() as s:\n",
    "        s.layers.append(name='im', layer=ngLayer(im, res, tt='image'))\n",
    "        s.layers.append(name='gt', layer=ngLayer(gt, res, tt='segmentation'))\n",
    "        # all_unique_ids = np.unique(gt)\n",
    "        # for id in all_unique_ids:\n",
    "        #     s.layers['segmentation'].segments.add(id)\n",
    "\n",
    "    print(viewer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(seg_24_output_file, 'r') as fl:\n",
    "    tmp_dataset = fl[seg_dataset_name]\n",
    "    images = []\n",
    "    for i in range(n):\n",
    "        images.append(tmp_dataset[i])\n",
    "    seg_24_dataset = np.array(images, dtype=np.uint32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_unique_channels = []\n",
    "for i in range(3):\n",
    "    all_unique_channels.append(np.unique(seg_24_dataset[:, :, :, i]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "240685280"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(seg_24_dataset[:, :, :, 1] != seg_24_dataset[:, :, :, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load raw image and segmentation.\n",
      "(10, 15260, 15217) (10, 15260, 15217, 3)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "rank of data (4) must match rank of coordinate space (3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mneuroglancer_visualize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_output_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseg_24_output_file\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[11], line 43\u001b[0m, in \u001b[0;36mneuroglancer_visualize\u001b[0;34m(raw_output_file, seg_output_file)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m viewer\u001b[38;5;241m.\u001b[39mtxn() \u001b[38;5;28;01mas\u001b[39;00m s:\n\u001b[1;32m     42\u001b[0m     s\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mappend(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mim\u001b[39m\u001b[38;5;124m'\u001b[39m, layer\u001b[38;5;241m=\u001b[39mngLayer(im, res, tt\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m---> 43\u001b[0m     s\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mappend(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgt\u001b[39m\u001b[38;5;124m'\u001b[39m, layer\u001b[38;5;241m=\u001b[39m\u001b[43mngLayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mres\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msegmentation\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;66;03m# all_unique_ids = np.unique(gt)\u001b[39;00m\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;66;03m# for id in all_unique_ids:\u001b[39;00m\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;66;03m#     s.layers['segmentation'].segments.add(id)\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28mprint\u001b[39m(viewer)\n",
      "Cell \u001b[0;32mIn[11], line 39\u001b[0m, in \u001b[0;36mneuroglancer_visualize.<locals>.ngLayer\u001b[0;34m(data, res, oo, tt)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mngLayer\u001b[39m(data, res, oo\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m], tt\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msegmentation\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m---> 39\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mneuroglancer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLocalVolume\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdimensions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mres\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvolume_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvoxel_offset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moo\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/yuxuan_exp/yuxuan_env/lib/python3.10/site-packages/neuroglancer/local_volume.py:112\u001b[0m, in \u001b[0;36mLocalVolume.__init__\u001b[0;34m(self, data, dimensions, volume_type, voxel_offset, encoding, max_voxels_per_chunk_log2, mesh_options, downsampling, chunk_layout, max_downsampling, max_downsampled_size, max_downsampling_scales)\u001b[0m\n\u001b[1;32m    106\u001b[0m     dimensions \u001b[38;5;241m=\u001b[39m CoordinateSpace(\n\u001b[1;32m    107\u001b[0m         names\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mlabels,\n\u001b[1;32m    108\u001b[0m         units\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39munits,\n\u001b[1;32m    109\u001b[0m         scales\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mscales,\n\u001b[1;32m    110\u001b[0m     )\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m rank \u001b[38;5;241m!=\u001b[39m dimensions\u001b[38;5;241m.\u001b[39mrank:\n\u001b[0;32m--> 112\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    113\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrank of data (\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m) must match rank of coordinate space (\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    114\u001b[0m         \u001b[38;5;241m%\u001b[39m (rank, dimensions\u001b[38;5;241m.\u001b[39mrank)\n\u001b[1;32m    115\u001b[0m     )\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m voxel_offset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    117\u001b[0m     voxel_offset \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39morigin, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mint64)\n",
      "\u001b[0;31mValueError\u001b[0m: rank of data (4) must match rank of coordinate space (3)"
     ]
    }
   ],
   "source": [
    "neuroglancer_visualize(raw_output_file, seg_24_output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PS: You could also directly use the GUI of the web-based application to load diverse datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tifffile in /home/mitochondria/Desktop/yuxuan_exp/yuxuan_env/lib/python3.10/site-packages (2024.7.24)\n",
      "Requirement already satisfied: numpy in /home/mitochondria/Desktop/yuxuan_exp/yuxuan_env/lib/python3.10/site-packages (from tifffile) (1.26.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install tifffile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neuroglancer Tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - Experiment with 32 bit SNEMI\n",
    "import os\n",
    "from PIL import Image\n",
    "from tifffile import *\n",
    "import numpy as np\n",
    "D0='./SNEMI_example/'\n",
    "# raw_input_path = D0+'train-input.tif'\n",
    "label_input_path = D0+'train-labels.tif'\n",
    "\n",
    "label_output_path = D0 + 'train-lables-32bit.tif'\n",
    "\n",
    "image_stack = imread(label_input_path)\n",
    "image_stack_uint32 = image_stack.astype(np.uint32)\n",
    "imwrite(label_output_path, image_stack, photometric='minisblack')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I;16B\n"
     ]
    }
   ],
   "source": [
    "with Image.open(label_input_path) as img:\n",
    "    print(img.mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('<u2')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_stack.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load im and gt segmentation\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "No such file: '/home/mitochondria/Desktop/yuxuan_exp/neuroglancer_tools/SNEMI_example/train-lables.tif'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 21\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mload im and gt segmentation\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     20\u001b[0m im \u001b[38;5;241m=\u001b[39m imageio\u001b[38;5;241m.\u001b[39mvolread(D0\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain-input.tif\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 21\u001b[0m gt \u001b[38;5;241m=\u001b[39m \u001b[43mimageio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvolread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mD0\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain-lables.tif\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(im\u001b[38;5;241m.\u001b[39mshape, gt\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mngLayer\u001b[39m(data,res,oo\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m],tt\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msegmentation\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "File \u001b[0;32m~/Desktop/yuxuan_exp/yuxuan_env/lib/python3.10/site-packages/imageio/v2.py:522\u001b[0m, in \u001b[0;36mvolread\u001b[0;34m(uri, format, **kwargs)\u001b[0m\n\u001b[1;32m    520\u001b[0m imopen_args \u001b[38;5;241m=\u001b[39m decypher_format_arg(\u001b[38;5;28mformat\u001b[39m)\n\u001b[1;32m    521\u001b[0m imopen_args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlegacy_mode\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 522\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mimopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43muri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mimopen_args\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m    523\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m file\u001b[38;5;241m.\u001b[39mread(index\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/Desktop/yuxuan_exp/yuxuan_env/lib/python3.10/site-packages/imageio/core/imopen.py:113\u001b[0m, in \u001b[0;36mimopen\u001b[0;34m(uri, io_mode, plugin, extension, format_hint, legacy_mode, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m     request\u001b[38;5;241m.\u001b[39mformat_hint \u001b[38;5;241m=\u001b[39m format_hint\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 113\u001b[0m     request \u001b[38;5;241m=\u001b[39m \u001b[43mRequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43muri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mio_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformat_hint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mformat_hint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextension\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextension\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    115\u001b[0m source \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<bytes>\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(uri, \u001b[38;5;28mbytes\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m uri\n\u001b[1;32m    117\u001b[0m \u001b[38;5;66;03m# fast-path based on plugin\u001b[39;00m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;66;03m# (except in legacy mode)\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/yuxuan_exp/yuxuan_env/lib/python3.10/site-packages/imageio/core/request.py:247\u001b[0m, in \u001b[0;36mRequest.__init__\u001b[0;34m(self, uri, mode, extension, format_hint, **kwargs)\u001b[0m\n\u001b[1;32m    244\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Request.Mode: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmode\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    246\u001b[0m \u001b[38;5;66;03m# Parse what was given\u001b[39;00m\n\u001b[0;32m--> 247\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parse_uri\u001b[49m\u001b[43m(\u001b[49m\u001b[43muri\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# Set extension\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m extension \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Desktop/yuxuan_exp/yuxuan_env/lib/python3.10/site-packages/imageio/core/request.py:407\u001b[0m, in \u001b[0;36mRequest._parse_uri\u001b[0;34m(self, uri)\u001b[0m\n\u001b[1;32m    404\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_read_request:\n\u001b[1;32m    405\u001b[0m     \u001b[38;5;66;03m# Reading: check that the file exists (but is allowed a dir)\u001b[39;00m\n\u001b[1;32m    406\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(fn):\n\u001b[0;32m--> 407\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo such file: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m fn)\n\u001b[1;32m    408\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    409\u001b[0m     \u001b[38;5;66;03m# Writing: check that the directory to write to does exist\u001b[39;00m\n\u001b[1;32m    410\u001b[0m     dn \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(fn)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: No such file: '/home/mitochondria/Desktop/yuxuan_exp/neuroglancer_tools/SNEMI_example/train-lables.tif'"
     ]
    }
   ],
   "source": [
    "# - Experiment with SNEMI\n",
    "import neuroglancer\n",
    "import numpy as np\n",
    "import imageio\n",
    "import h5py\n",
    "\n",
    "ip = 'localhost' #or public IP of the machine for sharable display\n",
    "port = 9999 #change to an unused port number\n",
    "neuroglancer.set_server_bind_address(bind_address=ip,bind_port=port)\n",
    "viewer=neuroglancer.Viewer()\n",
    "\n",
    "# SNEMI (# 3d vol dim: z,y,x)\n",
    "D0='./SNEMI_example/'\n",
    "res = neuroglancer.CoordinateSpace(\n",
    "        names=['z', 'y', 'x'],\n",
    "        units=['nm', 'nm', 'nm'],\n",
    "        scales=[30, 6, 6])\n",
    "\n",
    "print('load im and gt segmentation')\n",
    "im = imageio.volread(D0+'train-input.tif')\n",
    "gt = imageio.volread(D0+'train-lables.tif')\n",
    "print(im.shape, gt.shape)\n",
    "\n",
    "def ngLayer(data,res,oo=[0,0,0],tt='segmentation'):\n",
    "    return neuroglancer.LocalVolume(data,dimensions=res,volume_type=tt,voxel_offset=oo)\n",
    "\n",
    "with viewer.txn() as s:\n",
    "    s.layers.append(name='im',layer=ngLayer(im,res,tt='image'))\n",
    "    s.layers.append(name='gt',layer=ngLayer(gt,res,tt='segmentation'))\n",
    "\n",
    "print(viewer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yuxuan_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
